{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fastcore.basics import Path, AttrDict\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# This is used to import the evaluation script, not needed for training\n",
    "import sys\n",
    "sys.path.append('../') \n",
    "# import evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AttrDict(\n",
    "    challenge_data_raw_dir = Path('../../data/1_dataset_raw/'),\n",
    "    challenge_data_clean_dir = Path('../../data/2_dataset_clean/'),\n",
    "    challenge_data_processed_dir = Path('../../data/3_dataset_processed/'),\n",
    "    challenge_data_features_dir = Path('../../data/4_dataset_features/'),\n",
    "    valid_ratio = 0.1,\n",
    "    lag_steps = 5,\n",
    "    tolerance= 6, # Default evaluation tolerance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of feature columns\n",
    "feature_cols = [\n",
    "    \"Eccentricity\",\n",
    "    \"Semimajor Axis (m)\",\n",
    "    \"Inclination (deg)\",\n",
    "    \"RAAN (deg)\",\n",
    "    \"Argument of Periapsis (deg)\",\n",
    "    \"True Anomaly (deg)\",\n",
    "    \"Latitude (deg)\",\n",
    "    \"Longitude (deg)\",\n",
    "    \"Altitude (m)\",\n",
    "    \"X (m)\",\n",
    "    \"Y (m)\",\n",
    "    \"Z (m)\",\n",
    "    \"Vx (m/s)\",\n",
    "    \"Vy (m/s)\",\n",
    "    \"Vz (m/s)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths\n",
    "train_data_dir = config.challenge_data_raw_dir / \"train\"\n",
    "# Load the ground truth data\n",
    "ground_truth = pd.read_csv(config.challenge_data_raw_dir / 'train_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fastcore.basics import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_ground_truth_with_trajectories(train_data_dir, ground_truth, number_of_files_to_process=10):\n",
    "    merged_data = pd.DataFrame()\n",
    "    test_data = Path(train_data_dir).glob('*.csv')\n",
    "\n",
    "\n",
    "    number_of_files_processed = 0\n",
    "    for data_file in test_data:\n",
    "        number_of_files_processed += 1\n",
    "        if number_of_files_processed > number_of_files_to_process:\n",
    "            break\n",
    "        \n",
    "        data_df = pd.read_csv(data_file)\n",
    "        data_df['ObjectID'] = int(data_file.stem)\n",
    "        data_df['TimeIndex'] = range(len(data_df))\n",
    "        \n",
    "        ground_truth_object = ground_truth[ground_truth['ObjectID'] == data_df['ObjectID'][0]].copy()\n",
    "        # Separate the 'EW' and 'NS' types in the ground truth\n",
    "        ground_truth_EW = ground_truth_object[ground_truth_object['Direction'] == 'EW'].copy()\n",
    "        ground_truth_NS = ground_truth_object[ground_truth_object['Direction'] == 'NS'].copy()\n",
    "        \n",
    "        # Create 'EW' and 'NS' labels and fill 'unknown' values\n",
    "        ground_truth_EW['EW'] = ground_truth_EW['Node'] + '-' + ground_truth_EW['Type']\n",
    "        ground_truth_NS['NS'] = ground_truth_NS['Node'] + '-' + ground_truth_NS['Type']\n",
    "        ground_truth_EW.drop(['Node', 'Type', 'Direction'], axis=1, inplace=True)\n",
    "        ground_truth_NS.drop(['Node', 'Type', 'Direction'], axis=1, inplace=True)\n",
    "        \n",
    "        # Merge the input data with the ground truth\n",
    "        merged_df = pd.merge(data_df, \n",
    "                            ground_truth_EW.sort_values('TimeIndex'), \n",
    "                            on=['TimeIndex', 'ObjectID'],\n",
    "                            how='left')\n",
    "        \n",
    "        merged_df = pd.merge_ordered(merged_df, \n",
    "                                    ground_truth_NS.sort_values('TimeIndex'), \n",
    "                                    on=['TimeIndex', 'ObjectID'],\n",
    "                                    how='left')\n",
    "\n",
    "                \n",
    "        merged_data = pd.concat([merged_data, merged_df])\n",
    "        \n",
    "    return merged_data\n",
    "    \n",
    "df_merged_small = merge_ground_truth_with_trajectories(train_data_dir, ground_truth, number_of_files_to_process=500)\n",
    "df_merged_medium = merge_ground_truth_with_trajectories(train_data_dir, ground_truth, number_of_files_to_process=1000)\n",
    "df_merged_large = merge_ground_truth_with_trajectories(train_data_dir, ground_truth, number_of_files_to_process=1500)\n",
    "df_merged_full = merge_ground_truth_with_trajectories(train_data_dir, ground_truth, number_of_files_to_process=2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.challenge_data_clean_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def export_df_to_csv(df, name):\n",
    "    df.to_csv(name, index=False)\n",
    "    \n",
    "export_df_to_csv(df_merged_small, config.challenge_data_clean_dir / 'df_merged_small.csv')\n",
    "export_df_to_csv(df_merged_medium, config.challenge_data_clean_dir / 'df_merged_medium.csv')\n",
    "export_df_to_csv(df_merged_large, config.challenge_data_clean_dir / 'df_merged_large.csv')\n",
    "export_df_to_csv(df_merged_full, config.challenge_data_clean_dir / 'df_merged_full.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
